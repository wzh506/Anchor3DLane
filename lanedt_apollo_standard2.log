nohup: ignoring input
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
2025-05-22 10:08:53,790 - mmseg - INFO - Multi-processing start method is `None`
2025-05-22 10:08:53,796 - mmseg - INFO - OpenCV num_threads is `160
2025-05-22 10:08:53,796 - mmseg - INFO - OMP num threads is 1
2025-05-22 10:08:53,864 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.9.21 (main, Dec 11 2024, 16:24:11) [GCC 11.2.0]
CUDA available: True
GPU 0,1,2,3,4,5,6,7: NVIDIA H20
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 12.4, V12.4.131
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
PyTorch: 2.4.0+cu124
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

TorchVision: 0.19.0+cu124
OpenCV: 4.11.0
MMCV: 1.7.2
MMCV Compiler: GCC 9.4
MMCV CUDA Compiler: 12.4
MMSegmentation: 0.26.0+5cdf06e
------------------------------------------------------------

2025-05-22 10:08:53,864 - mmseg - INFO - Distributed training: True
2025-05-22 10:08:54,350 - mmseg - INFO - Config:
dataset_type = 'APOLLOSIMDataset'
data_root = 'data/ApolloSim'
split = 'standard'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
input_size = (360, 480)
feat_y_steps = [5, 10, 15, 20, 30, 40, 50, 60, 80, 100]
anchor_y_steps = [5, 10, 15, 20, 30, 40, 50, 60, 80, 100]
anchor_len = 10
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='Resize', img_scale=(480, 360), keep_ratio=False),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='MaskGenerate', input_size=(360, 480)),
    dict(type='LaneFormat'),
    dict(
        type='Collect',
        keys=['img', 'img_metas', 'gt_3dlanes', 'gt_project_matrix', 'mask'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='Resize', img_scale=(480, 360), keep_ratio=False),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='MaskGenerate', input_size=(360, 480)),
    dict(type='LaneFormat'),
    dict(
        type='Collect',
        keys=['img', 'img_metas', 'gt_3dlanes', 'gt_project_matrix', 'mask'])
]
dataset_config = dict(max_lanes=7, input_size=(360, 480))
data = dict(
    samples_per_gpu=32,
    workers_per_gpu=4,
    train=dict(
        type='APOLLOSIMDataset',
        data_root='data/ApolloSim',
        data_list='test.txt',
        y_steps=[5, 10, 15, 20, 30, 40, 50, 60, 80, 100],
        dataset_config=dict(max_lanes=7, input_size=(360, 480)),
        split='standard',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Resize', img_scale=(480, 360), keep_ratio=False),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='MaskGenerate', input_size=(360, 480)),
            dict(type='LaneFormat'),
            dict(
                type='Collect',
                keys=[
                    'img', 'img_metas', 'gt_3dlanes', 'gt_project_matrix',
                    'mask'
                ])
        ]),
    test=dict(
        type='APOLLOSIMDataset',
        data_root='data/ApolloSim',
        data_list='test.txt',
        dataset_config=dict(max_lanes=7, input_size=(360, 480)),
        y_steps=[5, 10, 15, 20, 30, 40, 50, 60, 80, 100],
        split='standard',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Resize', img_scale=(480, 360), keep_ratio=False),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='MaskGenerate', input_size=(360, 480)),
            dict(type='LaneFormat'),
            dict(
                type='Collect',
                keys=[
                    'img', 'img_metas', 'gt_3dlanes', 'gt_project_matrix',
                    'mask'
                ])
        ],
        test_mode=True))
model = dict(
    type='Anchor3DLane',
    backbone=dict(
        type='ResNetV1c',
        depth=18,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        dilations=(1, 1, 2, 4),
        strides=(1, 2, 1, 1),
        style='pytorch'),
    pretrained='pretrained/resnet18_v1c-b5776b93.pth',
    y_steps=[5, 10, 15, 20, 30, 40, 50, 60, 80, 100],
    feat_y_steps=[5, 10, 15, 20, 30, 40, 50, 60, 80, 100],
    anchor_cfg=dict(
        pitches=[5, 2, 1, 0, -1, -2, -5],
        yaws=[
            30, 20, 15, 10, 7, 5, 3, 1, 0, -1, -3, -5, -7, -10, -15, -20, -30
        ],
        num_x=45,
        distances=[3]),
    db_cfg=dict(
        org_h=1080,
        org_w=1920,
        resize_h=360,
        resize_w=480,
        ipm_h=208,
        ipm_w=128,
        pitch=3,
        cam_height=1.55,
        crop_y=0,
        K=[[2015.0, 0.0, 960.0], [0.0, 2015.0, 540.0], [0.0, 0.0, 1.0]],
        top_view_region=[[-10, 103], [10, 103], [-10, 3], [10, 3]],
        max_2dpoints=10),
    attn_dim=64,
    iter_reg=1,
    drop_out=0.0,
    num_heads=2,
    dim_feedforward=128,
    pre_norm=False,
    feat_size=(45, 60),
    num_category=2,
    loss_lane=dict(
        type='LaneLoss',
        loss_weights=dict(
            cls_loss=2, reg_losses_x=2, reg_losses_z=2, reg_losses_vis=2),
        assign_cfg=dict(
            type='TopkAssigner',
            pos_k=2,
            neg_k=450,
            anchor_len=10,
            metric='Euclidean'),
        anchor_len=10,
        anchor_steps=[5, 10, 15, 20, 30, 40, 50, 60, 80, 100],
        anchor_assign=False),
    loss_aux=[
        dict(
            type='LaneLoss',
            loss_weights=dict(
                cls_loss=1, reg_losses_x=1, reg_losses_z=1, reg_losses_vis=1),
            assign_cfg=dict(
                type='TopkAssigner',
                pos_k=3,
                neg_k=450,
                anchor_len=10,
                metric='Euclidean'),
            anchor_len=10,
            anchor_steps=[5, 10, 15, 20, 30, 40, 50, 60, 80, 100])
    ],
    train_cfg=dict(nms_thres=0, conf_threshold=0),
    test_cfg=dict(
        nms_thres=2,
        conf_threshold=0.5,
        test_conf=0.7,
        refine_vis=True,
        vis_thresh=0.5))
data_shuffle = True
optimizer = dict(type='Adam', lr=0.0001)
optimizer_config = dict()
lr_config = dict(policy='step', step=[45000], by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=50000)
checkpoint_config = dict(by_epoch=False, interval=2500)
log_config = dict(
    interval=10,
    hooks=[
        dict(type='TextLoggerHook', by_epoch=False),
        dict(type='TensorboardLoggerHook')
    ])
dist_params = dict(backend='nccl')
log_level = 'INFO'
resume_from = None
workflow = [('train', 10000000)]
cudnn_benchmark = True
load_from = 'pretrained/apollo_anchor3dlane.pth'
work_dir = 'output/apollosim/lanedt/standard'
gpu_ids = range(0, 8)
auto_resume = True

2025-05-22 10:09:04,411 - mmseg - INFO - Set random seed to 1655998163, deterministic: False
anchor: 4431
anchor: 4431
anchor: 4431
anchor: 4431
anchor: 4431
anchor: 4431
anchor: 4431
anchor: 4431
/home/zhaohui1.wang/github/Anchor3DLane/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is a deprecated, '
/home/zhaohui1.wang/github/Anchor3DLane/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is a deprecated, '
/home/zhaohui1.wang/github/Anchor3DLane/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is a deprecated, '
/home/zhaohui1.wang/github/Anchor3DLane/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is a deprecated, '
/home/zhaohui1.wang/github/Anchor3DLane/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is a deprecated, '
/home/zhaohui1.wang/github/Anchor3DLane/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is a deprecated, '
/home/zhaohui1.wang/github/Anchor3DLane/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is a deprecated, '
/home/zhaohui1.wang/github/Anchor3DLane/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is a deprecated, '
2025-05-22 10:09:04,589 - mmcv - INFO - initialize ResNetV1c with init_cfg {'type': 'Pretrained', 'checkpoint': 'pretrained/resnet18_v1c-b5776b93.pth'}
2025-05-22 10:09:04,589 - mmcv - INFO - initialize ResNetV1c with init_cfg {'type': 'Pretrained', 'checkpoint': 'pretrained/resnet18_v1c-b5776b93.pth'}
2025-05-22 10:09:04,589 - mmcv - INFO - load model from: pretrained/resnet18_v1c-b5776b93.pth
2025-05-22 10:09:04,589 - mmcv - INFO - load model from: pretrained/resnet18_v1c-b5776b93.pth
2025-05-22 10:09:04,590 - mmcv - INFO - initialize ResNetV1c with init_cfg {'type': 'Pretrained', 'checkpoint': 'pretrained/resnet18_v1c-b5776b93.pth'}
2025-05-22 10:09:04,590 - mmcv - INFO - initialize ResNetV1c with init_cfg {'type': 'Pretrained', 'checkpoint': 'pretrained/resnet18_v1c-b5776b93.pth'}
2025-05-22 10:09:04,590 - mmcv - INFO - initialize ResNetV1c with init_cfg {'type': 'Pretrained', 'checkpoint': 'pretrained/resnet18_v1c-b5776b93.pth'}
2025-05-22 10:09:04,590 - mmcv - INFO - load checkpoint from local path: pretrained/resnet18_v1c-b5776b93.pth
2025-05-22 10:09:04,590 - mmcv - INFO - load model from: pretrained/resnet18_v1c-b5776b93.pth
2025-05-22 10:09:04,590 - mmcv - INFO - load model from: pretrained/resnet18_v1c-b5776b93.pth
2025-05-22 10:09:04,590 - mmcv - INFO - load checkpoint from local path: pretrained/resnet18_v1c-b5776b93.pth
2025-05-22 10:09:04,590 - mmcv - INFO - load model from: pretrained/resnet18_v1c-b5776b93.pth
2025-05-22 10:09:04,590 - mmcv - INFO - initialize ResNetV1c with init_cfg {'type': 'Pretrained', 'checkpoint': 'pretrained/resnet18_v1c-b5776b93.pth'}
2025-05-22 10:09:04,590 - mmcv - INFO - load model from: pretrained/resnet18_v1c-b5776b93.pth
2025-05-22 10:09:04,590 - mmcv - INFO - initialize ResNetV1c with init_cfg {'type': 'Pretrained', 'checkpoint': 'pretrained/resnet18_v1c-b5776b93.pth'}
2025-05-22 10:09:04,590 - mmcv - INFO - load model from: pretrained/resnet18_v1c-b5776b93.pth
2025-05-22 10:09:04,590 - mmcv - INFO - load checkpoint from local path: pretrained/resnet18_v1c-b5776b93.pth
2025-05-22 10:09:04,590 - mmcv - INFO - load checkpoint from local path: pretrained/resnet18_v1c-b5776b93.pth
2025-05-22 10:09:04,591 - mmcv - INFO - load checkpoint from local path: pretrained/resnet18_v1c-b5776b93.pth
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/runner/checkpoint.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(filename, map_location=map_location)
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/runner/checkpoint.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(filename, map_location=map_location)
2025-05-22 10:09:04,591 - mmcv - INFO - load checkpoint from local path: pretrained/resnet18_v1c-b5776b93.pth
2025-05-22 10:09:04,591 - mmcv - INFO - load checkpoint from local path: pretrained/resnet18_v1c-b5776b93.pth
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/runner/checkpoint.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(filename, map_location=map_location)
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/runner/checkpoint.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(filename, map_location=map_location)
2025-05-22 10:09:04,591 - mmcv - INFO - initialize ResNetV1c with init_cfg {'type': 'Pretrained', 'checkpoint': 'pretrained/resnet18_v1c-b5776b93.pth'}
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/runner/checkpoint.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(filename, map_location=map_location)
2025-05-22 10:09:04,591 - mmcv - INFO - load model from: pretrained/resnet18_v1c-b5776b93.pth
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/runner/checkpoint.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(filename, map_location=map_location)
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/runner/checkpoint.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(filename, map_location=map_location)
2025-05-22 10:09:04,592 - mmcv - INFO - load checkpoint from local path: pretrained/resnet18_v1c-b5776b93.pth
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/runner/checkpoint.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(filename, map_location=map_location)
2025-05-22 10:09:04,630 - mmcv - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

Now loading annotations...
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.stem.0.weight - torch.Size([32, 3, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.stem.1.weight - torch.Size([32]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.stem.1.bias - torch.Size([32]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.stem.3.weight - torch.Size([32, 32, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.stem.4.weight - torch.Size([32]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.stem.4.bias - torch.Size([32]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.stem.6.weight - torch.Size([64, 32, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.stem.7.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.stem.7.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer1.0.conv1.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer1.0.bn1.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer1.0.bn1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer1.0.bn2.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer1.0.bn2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer1.1.conv1.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer1.1.bn1.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer1.1.bn1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer1.1.bn2.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer1.1.bn2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer2.0.conv1.weight - torch.Size([128, 64, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer2.0.bn1.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer2.0.bn1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer2.0.bn2.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer2.0.bn2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer2.0.downsample.0.weight - torch.Size([128, 64, 1, 1]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer2.0.downsample.1.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer2.0.downsample.1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer2.1.conv1.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer2.1.bn1.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer2.1.bn1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer2.1.bn2.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer2.1.bn2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer3.0.conv1.weight - torch.Size([256, 128, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer3.0.bn1.weight - torch.Size([256]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,639 - mmcv - INFO - 
backbone.layer3.0.bn1.bias - torch.Size([256]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer3.0.bn2.weight - torch.Size([256]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer3.0.bn2.bias - torch.Size([256]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer3.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer3.0.downsample.1.weight - torch.Size([256]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer3.0.downsample.1.bias - torch.Size([256]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer3.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer3.1.bn1.weight - torch.Size([256]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer3.1.bn1.bias - torch.Size([256]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer3.1.bn2.weight - torch.Size([256]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer3.1.bn2.bias - torch.Size([256]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer4.0.conv1.weight - torch.Size([512, 256, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer4.0.bn1.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
Now loading annotations...Now loading annotations...2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer4.0.bn1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 


2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer4.0.bn2.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer4.0.bn2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer4.0.downsample.1.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer4.0.downsample.1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer4.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer4.1.bn1.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer4.1.bn1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer4.1.bn2.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
backbone.layer4.1.bn2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
input_proj.weight - torch.Size([64, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
input_proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
transformer_layer.self_attn.in_proj_weight - torch.Size([192, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
transformer_layer.self_attn.in_proj_bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
transformer_layer.self_attn.out_proj.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
transformer_layer.self_attn.out_proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
transformer_layer.linear1.weight - torch.Size([128, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
transformer_layer.linear1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
transformer_layer.linear2.weight - torch.Size([64, 128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
transformer_layer.linear2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
transformer_layer.norm1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
transformer_layer.norm1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
transformer_layer.norm2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
transformer_layer.norm2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
anchor_projection.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
anchor_projection.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
cls_layer.0.layer.0.weight - torch.Size([640, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
cls_layer.0.layer.0.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
cls_layer.0.layer.2.weight - torch.Size([640, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
cls_layer.0.layer.2.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
cls_layer.0.layer.4.weight - torch.Size([2, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
cls_layer.0.layer.4.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
cls_layer.1.layer.0.weight - torch.Size([640, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
cls_layer.1.layer.0.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
cls_layer.1.layer.2.weight - torch.Size([640, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
cls_layer.1.layer.2.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
cls_layer.1.layer.4.weight - torch.Size([2, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
cls_layer.1.layer.4.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
reg_x_layer.0.layer.0.weight - torch.Size([64, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,640 - mmcv - INFO - 
reg_x_layer.0.layer.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_x_layer.0.layer.2.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_x_layer.0.layer.2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_x_layer.0.layer.4.weight - torch.Size([10, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_x_layer.0.layer.4.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_x_layer.1.layer.0.weight - torch.Size([64, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_x_layer.1.layer.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_x_layer.1.layer.2.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_x_layer.1.layer.2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_x_layer.1.layer.4.weight - torch.Size([10, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_x_layer.1.layer.4.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_z_layer.0.layer.0.weight - torch.Size([64, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_z_layer.0.layer.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_z_layer.0.layer.2.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_z_layer.0.layer.2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_z_layer.0.layer.4.weight - torch.Size([10, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_z_layer.0.layer.4.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_z_layer.1.layer.0.weight - torch.Size([64, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_z_layer.1.layer.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_z_layer.1.layer.2.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_z_layer.1.layer.2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_z_layer.1.layer.4.weight - torch.Size([10, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_z_layer.1.layer.4.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_vis_layer.0.layer.0.weight - torch.Size([64, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_vis_layer.0.layer.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_vis_layer.0.layer.2.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_vis_layer.0.layer.2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_vis_layer.0.layer.4.weight - torch.Size([10, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_vis_layer.0.layer.4.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_vis_layer.1.layer.0.weight - torch.Size([64, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_vis_layer.1.layer.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
Now loading annotations...2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_vis_layer.1.layer.2.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 

2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_vis_layer.1.layer.2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_vis_layer.1.layer.4.weight - torch.Size([10, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-22 10:09:04,641 - mmcv - INFO - 
reg_vis_layer.1.layer.4.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
Now loading annotations...
Now loading annotations...
Now loading annotations...
2025-05-22 10:09:04,641 - mmseg - INFO - Anchor3DLane(
  (backbone): ResNetV1c(
    (stem): Sequential(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): ResLayer(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): ResLayer(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): ResLayer(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): ResLayer(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Pretrained', 'checkpoint': 'pretrained/resnet18_v1c-b5776b93.pth'}
  (position_embedding): PositionEmbeddingSine()
  (input_proj): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
  (transformer_layer): TransformerEncoderLayer(
    (self_attn): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
    )
    (linear1): Linear(in_features=64, out_features=128, bias=True)
    (dropout): Dropout(p=0.0, inplace=False)
    (linear2): Linear(in_features=128, out_features=64, bias=True)
    (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (dropout1): Dropout(p=0.0, inplace=False)
    (dropout2): Dropout(p=0.0, inplace=False)
  )
  (anchor_projection): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
  (cls_layer): ModuleList(
    (0-1): 2 x DecodeLayer(
      (layer): Sequential(
        (0): Linear(in_features=640, out_features=640, bias=True)
        (1): ReLU6()
        (2): Linear(in_features=640, out_features=640, bias=True)
        (3): ReLU6()
        (4): Linear(in_features=640, out_features=2, bias=True)
      )
    )
  )
  (reg_x_layer): ModuleList(
    (0-1): 2 x DecodeLayer(
      (layer): Sequential(
        (0): Linear(in_features=640, out_features=64, bias=True)
        (1): ReLU6()
        (2): Linear(in_features=64, out_features=64, bias=True)
        (3): ReLU6()
        (4): Linear(in_features=64, out_features=10, bias=True)
      )
    )
  )
  (reg_z_layer): ModuleList(
    (0-1): 2 x DecodeLayer(
      (layer): Sequential(
        (0): Linear(in_features=640, out_features=64, bias=True)
        (1): ReLU6()
        (2): Linear(in_features=64, out_features=64, bias=True)
        (3): ReLU6()
        (4): Linear(in_features=64, out_features=10, bias=True)
      )
    )
  )
  (reg_vis_layer): ModuleList(
    (0-1): 2 x DecodeLayer(
      (layer): Sequential(
        (0): Linear(in_features=640, out_features=64, bias=True)
        (1): ReLU6()
        (2): Linear(in_features=64, out_features=64, bias=True)
        (3): ReLU6()
        (4): Linear(in_features=64, out_features=10, bias=True)
      )
    )
  )
  (lane_loss): LaneLoss()
  (aux_loss): ModuleList(
    (0): LaneLoss()
  )
)
Now loading annotations...
0it [00:00, ?it/s]0it [00:00, ?it/s]0it [00:00, ?it/s]0it [00:00, ?it/s]0it [00:00, ?it/s]0it [00:00, ?it/s]1496it [00:00, 414033.57it/s]
after load annotation
find 1496 samples in data/ApolloSim/data_lists/standard/test.txt.
1496it [00:00, 429184.60it/s]
after load annotation
find 1496 samples in data/ApolloSim/data_lists/standard/test.txt.
0it [00:00, ?it/s]0it [00:00, ?it/s]1496it [00:00, 420498.51it/s]
after load annotation
find 1496 samples in data/ApolloSim/data_lists/standard/test.txt.
1496it [00:00, 420583.07it/s]
after load annotation
find 1496 samples in data/ApolloSim/data_lists/standard/test.txt.
1496it [00:00, 422224.53it/s]
after load annotation
find 1496 samples in data/ApolloSim/data_lists/standard/test.txt.
1496it [00:00, 417393.65it/s]
after load annotation
find 1496 samples in data/ApolloSim/data_lists/standard/test.txt.
1496it [00:00, 422139.32it/s]
1496it [00:00, 418507.22it/s]
after load annotation
find 1496 samples in data/ApolloSim/data_lists/standard/test.txt.
after load annotation
find 1496 samples in data/ApolloSim/data_lists/standard/test.txt.
2025-05-22 10:09:04,694 - mmseg - INFO - optimized parameters:
2025-05-22 10:09:04,694 - mmseg - INFO - backbone.stem.0.weight
2025-05-22 10:09:04,694 - mmseg - INFO - backbone.stem.1.weight
2025-05-22 10:09:04,694 - mmseg - INFO - backbone.stem.1.bias
2025-05-22 10:09:04,694 - mmseg - INFO - backbone.stem.3.weight
2025-05-22 10:09:04,694 - mmseg - INFO - backbone.stem.4.weight
2025-05-22 10:09:04,694 - mmseg - INFO - backbone.stem.4.bias
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.stem.6.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.stem.7.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.stem.7.bias
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer1.0.conv1.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer1.0.bn1.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer1.0.bn1.bias
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer1.0.conv2.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer1.0.bn2.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer1.0.bn2.bias
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer1.1.conv1.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer1.1.bn1.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer1.1.bn1.bias
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer1.1.conv2.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer1.1.bn2.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer1.1.bn2.bias
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer2.0.conv1.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer2.0.bn1.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer2.0.bn1.bias
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer2.0.conv2.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer2.0.bn2.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer2.0.bn2.bias
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer2.0.downsample.0.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer2.0.downsample.1.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer2.0.downsample.1.bias
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer2.1.conv1.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer2.1.bn1.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer2.1.bn1.bias
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer2.1.conv2.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer2.1.bn2.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer2.1.bn2.bias
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer3.0.conv1.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer3.0.bn1.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer3.0.bn1.bias
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer3.0.conv2.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer3.0.bn2.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer3.0.bn2.bias
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer3.0.downsample.0.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer3.0.downsample.1.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer3.0.downsample.1.bias
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer3.1.conv1.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer3.1.bn1.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer3.1.bn1.bias
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer3.1.conv2.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer3.1.bn2.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer3.1.bn2.bias
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer4.0.conv1.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer4.0.bn1.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer4.0.bn1.bias
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer4.0.conv2.weight
2025-05-22 10:09:04,695 - mmseg - INFO - backbone.layer4.0.bn2.weight
2025-05-22 10:09:04,696 - mmseg - INFO - backbone.layer4.0.bn2.bias
2025-05-22 10:09:04,696 - mmseg - INFO - backbone.layer4.0.downsample.0.weight
2025-05-22 10:09:04,696 - mmseg - INFO - backbone.layer4.0.downsample.1.weight
2025-05-22 10:09:04,696 - mmseg - INFO - backbone.layer4.0.downsample.1.bias
2025-05-22 10:09:04,696 - mmseg - INFO - backbone.layer4.1.conv1.weight
2025-05-22 10:09:04,696 - mmseg - INFO - backbone.layer4.1.bn1.weight
2025-05-22 10:09:04,696 - mmseg - INFO - backbone.layer4.1.bn1.bias
2025-05-22 10:09:04,696 - mmseg - INFO - backbone.layer4.1.conv2.weight
2025-05-22 10:09:04,696 - mmseg - INFO - backbone.layer4.1.bn2.weight
2025-05-22 10:09:04,696 - mmseg - INFO - backbone.layer4.1.bn2.bias
2025-05-22 10:09:04,696 - mmseg - INFO - input_proj.weight
2025-05-22 10:09:04,696 - mmseg - INFO - input_proj.bias
2025-05-22 10:09:04,696 - mmseg - INFO - transformer_layer.self_attn.in_proj_weight
2025-05-22 10:09:04,696 - mmseg - INFO - transformer_layer.self_attn.in_proj_bias
2025-05-22 10:09:04,696 - mmseg - INFO - transformer_layer.self_attn.out_proj.weight
2025-05-22 10:09:04,696 - mmseg - INFO - transformer_layer.self_attn.out_proj.bias
2025-05-22 10:09:04,696 - mmseg - INFO - transformer_layer.linear1.weight
2025-05-22 10:09:04,696 - mmseg - INFO - transformer_layer.linear1.bias
2025-05-22 10:09:04,696 - mmseg - INFO - transformer_layer.linear2.weight
2025-05-22 10:09:04,696 - mmseg - INFO - transformer_layer.linear2.bias
2025-05-22 10:09:04,696 - mmseg - INFO - transformer_layer.norm1.weight
2025-05-22 10:09:04,696 - mmseg - INFO - transformer_layer.norm1.bias
2025-05-22 10:09:04,696 - mmseg - INFO - transformer_layer.norm2.weight
2025-05-22 10:09:04,696 - mmseg - INFO - transformer_layer.norm2.bias
2025-05-22 10:09:04,696 - mmseg - INFO - anchor_projection.weight
2025-05-22 10:09:04,696 - mmseg - INFO - anchor_projection.bias
2025-05-22 10:09:04,696 - mmseg - INFO - cls_layer.0.layer.0.weight
2025-05-22 10:09:04,696 - mmseg - INFO - cls_layer.0.layer.0.bias
2025-05-22 10:09:04,696 - mmseg - INFO - cls_layer.0.layer.2.weight
2025-05-22 10:09:04,696 - mmseg - INFO - cls_layer.0.layer.2.bias
2025-05-22 10:09:04,696 - mmseg - INFO - cls_layer.0.layer.4.weight
2025-05-22 10:09:04,696 - mmseg - INFO - cls_layer.0.layer.4.bias
2025-05-22 10:09:04,696 - mmseg - INFO - cls_layer.1.layer.0.weight
2025-05-22 10:09:04,696 - mmseg - INFO - cls_layer.1.layer.0.bias
2025-05-22 10:09:04,696 - mmseg - INFO - cls_layer.1.layer.2.weight
2025-05-22 10:09:04,696 - mmseg - INFO - cls_layer.1.layer.2.bias
2025-05-22 10:09:04,696 - mmseg - INFO - cls_layer.1.layer.4.weight
2025-05-22 10:09:04,696 - mmseg - INFO - cls_layer.1.layer.4.bias
2025-05-22 10:09:04,696 - mmseg - INFO - reg_x_layer.0.layer.0.weight
2025-05-22 10:09:04,696 - mmseg - INFO - reg_x_layer.0.layer.0.bias
2025-05-22 10:09:04,696 - mmseg - INFO - reg_x_layer.0.layer.2.weight
2025-05-22 10:09:04,696 - mmseg - INFO - reg_x_layer.0.layer.2.bias
2025-05-22 10:09:04,696 - mmseg - INFO - reg_x_layer.0.layer.4.weight
2025-05-22 10:09:04,696 - mmseg - INFO - reg_x_layer.0.layer.4.bias
2025-05-22 10:09:04,696 - mmseg - INFO - reg_x_layer.1.layer.0.weight
2025-05-22 10:09:04,696 - mmseg - INFO - reg_x_layer.1.layer.0.bias
2025-05-22 10:09:04,696 - mmseg - INFO - reg_x_layer.1.layer.2.weight
2025-05-22 10:09:04,696 - mmseg - INFO - reg_x_layer.1.layer.2.bias
2025-05-22 10:09:04,696 - mmseg - INFO - reg_x_layer.1.layer.4.weight
2025-05-22 10:09:04,696 - mmseg - INFO - reg_x_layer.1.layer.4.bias
2025-05-22 10:09:04,696 - mmseg - INFO - reg_z_layer.0.layer.0.weight
2025-05-22 10:09:04,697 - mmseg - INFO - reg_z_layer.0.layer.0.bias
2025-05-22 10:09:04,697 - mmseg - INFO - reg_z_layer.0.layer.2.weight
2025-05-22 10:09:04,697 - mmseg - INFO - reg_z_layer.0.layer.2.bias
2025-05-22 10:09:04,697 - mmseg - INFO - reg_z_layer.0.layer.4.weight
2025-05-22 10:09:04,697 - mmseg - INFO - reg_z_layer.0.layer.4.bias
2025-05-22 10:09:04,697 - mmseg - INFO - reg_z_layer.1.layer.0.weight
2025-05-22 10:09:04,697 - mmseg - INFO - reg_z_layer.1.layer.0.bias
2025-05-22 10:09:04,697 - mmseg - INFO - reg_z_layer.1.layer.2.weight
2025-05-22 10:09:04,697 - mmseg - INFO - reg_z_layer.1.layer.2.bias
2025-05-22 10:09:04,697 - mmseg - INFO - reg_z_layer.1.layer.4.weight
2025-05-22 10:09:04,697 - mmseg - INFO - reg_z_layer.1.layer.4.bias
2025-05-22 10:09:04,697 - mmseg - INFO - reg_vis_layer.0.layer.0.weight
2025-05-22 10:09:04,697 - mmseg - INFO - reg_vis_layer.0.layer.0.bias
2025-05-22 10:09:04,697 - mmseg - INFO - reg_vis_layer.0.layer.2.weight
2025-05-22 10:09:04,697 - mmseg - INFO - reg_vis_layer.0.layer.2.bias
2025-05-22 10:09:04,697 - mmseg - INFO - reg_vis_layer.0.layer.4.weight
2025-05-22 10:09:04,697 - mmseg - INFO - reg_vis_layer.0.layer.4.bias
2025-05-22 10:09:04,697 - mmseg - INFO - reg_vis_layer.1.layer.0.weight
2025-05-22 10:09:04,697 - mmseg - INFO - reg_vis_layer.1.layer.0.bias
2025-05-22 10:09:04,697 - mmseg - INFO - reg_vis_layer.1.layer.2.weight
2025-05-22 10:09:04,697 - mmseg - INFO - reg_vis_layer.1.layer.2.bias
2025-05-22 10:09:04,697 - mmseg - INFO - reg_vis_layer.1.layer.4.weight
2025-05-22 10:09:04,697 - mmseg - INFO - reg_vis_layer.1.layer.4.bias
2025-05-22 10:09:04,698 - mmseg - INFO - load checkpoint from local path: output/apollosim/lanedt/standard/latest.pth
to run
to run
to run
to runto run

to run
2025-05-22 10:09:05,053 - mmseg - INFO - resumed from epoch: 4546, iter 49999
to run
2025-05-22 10:09:05,054 - mmseg - INFO - Start running, host: zhaohui1.wang@bare-20250107150309594-10-251-19-218, work_dir: /home/zhaohui1.wang/github/Anchor3DLane/output/apollosim/lanedt/standard
2025-05-22 10:09:05,054 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2025-05-22 10:09:05,054 - mmseg - INFO - workflow: [('train', 10000000)], max: 50000 iters
to run
2025-05-22 10:09:05,054 - mmseg - INFO - Checkpoints will be saved to /home/zhaohui1.wang/github/Anchor3DLane/output/apollosim/lanedt/standard by HardDiskBackend.
2025-05-22 10:09:05.332254: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-05-22 10:09:05.345022: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1747879745.358535   29898 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1747879745.362293   29898 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-05-22 10:09:05.378382: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/nn/functional.py:4373: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/nn/functional.py:4373: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/nn/functional.py:4373: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/nn/functional.py:4373: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/nn/functional.py:4373: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/nn/functional.py:4373: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/nn/functional.py:4373: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/nn/functional.py:4373: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
[rank2]:[W522 10:09:30.799037952 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank4]:[W522 10:09:30.799109703 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank0]:[W522 10:09:30.799140379 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank7]:[W522 10:09:30.799165539 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank5]:[W522 10:09:30.799169068 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank3]:[W522 10:09:30.799264500 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank6]:[W522 10:09:30.799428098 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank1]:[W522 10:09:30.800753111 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
2025-05-22 10:09:31,193 - mmseg - INFO - Saving checkpoint at 50000 iterations
2025-05-22 10:09:31,720 - mmseg - INFO - Exp name: lanedt.py
2025-05-22 10:09:31,720 - mmseg - INFO - Iter [50000/50000]	lr: 1.000e-05, eta: 0:00:00, time: 3.345, data_time: 0.929, memory: 12545, batch_positives: 9.0000, batch_negatives: 450.0000, cls_loss: 0.0082, reg_losses_x: 0.0003, reg_losses_z: 0.0001, reg_losses_vis: 0.0000, cls_loss0: 0.0000, reg_losses_x0: 0.0008, reg_losses_z0: 0.0003, reg_losses_vis0: 0.0000, loss: 0.0097
