nohup: ignoring input
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
Traceback (most recent call last):
  File "/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/runpy.py", line 197, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/distributed/run.py", line 905, in <module>
    main()
  File "/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 348, in wrapper
    return f(*args, **kwargs)
  File "/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/distributed/run.py", line 901, in main
    run(args)
  File "/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/distributed/run.py", line 892, in run
    elastic_launch(
  File "/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 133, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 255, in launch_agent
    result = agent.run()
  File "/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = f(*args, **kwargs)
  File "/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 680, in run
    result = self._invoke_run(role)
  File "/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 829, in _invoke_run
    self._initialize_workers(self._worker_group)
  File "/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = f(*args, **kwargs)
  File "/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 652, in _initialize_workers
    self._rendezvous(worker_group)
  File "/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 124, in wrapper
    result = f(*args, **kwargs)
  File "/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 489, in _rendezvous
    rdzv_info = spec.rdzv_handler.next_rendezvous()
  File "/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/distributed/elastic/rendezvous/static_tcp_rendezvous.py", line 66, in next_rendezvous
    self._store = TCPStore(  # type: ignore[call-arg]
RuntimeError: The server socket has failed to listen on any local network address. useIpv6: 0, code: -98, name: EADDRINUSE, message: address already in use
nohup: ignoring input
WARNING:__main__:
*****************************************
Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
*****************************************
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/__init__.py:20: UserWarning: On January 1, 2023, MMCV will release v2.0.0, in which it will remove components related to the training process and add a data transformation module. In addition, it will rename the package names mmcv to mmcv-lite and mmcv-full to mmcv. See https://github.com/open-mmlab/mmcv/blob/master/docs/en/compatibility.md for more details.
  warnings.warn(
2025-05-23 23:49:41,882 - mmseg - INFO - Multi-processing start method is `None`
2025-05-23 23:49:41,885 - mmseg - INFO - OpenCV num_threads is `160
2025-05-23 23:49:41,954 - mmseg - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.9.21 (main, Dec 11 2024, 16:24:11) [GCC 11.2.0]
CUDA available: True
GPU 0,1,2,3,4,5,6,7: NVIDIA H20
CUDA_HOME: /usr/local/cuda
NVCC: Cuda compilation tools, release 12.4, V12.4.131
GCC: gcc (Ubuntu 9.4.0-1ubuntu1~20.04.2) 9.4.0
PyTorch: 2.4.0+cu124
PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.4.2 (Git Hash 1137e04ec0b5251ca2b4400a4fd3c667ce843d67)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX512
  - CUDA Runtime 12.4
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90
  - CuDNN 90.1
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.4, CUDNN_VERSION=9.1.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.4.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

TorchVision: 0.19.0+cu124
OpenCV: 4.11.0
MMCV: 1.7.2
MMCV Compiler: GCC 9.4
MMCV CUDA Compiler: 12.4
MMSegmentation: 0.26.0+5cdf06e
------------------------------------------------------------

2025-05-23 23:49:41,954 - mmseg - INFO - Distributed training: True
2025-05-23 23:49:42,463 - mmseg - INFO - Config:
dataset_type = 'APOLLOSIMDataset'
data_root = 'data/ApolloSim'
split = 'standard'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
input_size = (360, 480)
feat_y_steps = [5, 10, 15, 20, 30, 40, 50, 60, 80, 100]
anchor_y_steps = [5, 10, 15, 20, 30, 40, 50, 60, 80, 100]
anchor_len = 10
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='Resize', img_scale=(480, 360), keep_ratio=False),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='MaskGenerate', input_size=(360, 480)),
    dict(type='LaneFormat'),
    dict(
        type='Collect',
        keys=['img', 'img_metas', 'gt_3dlanes', 'gt_project_matrix', 'mask'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='Resize', img_scale=(480, 360), keep_ratio=False),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='MaskGenerate', input_size=(360, 480)),
    dict(type='LaneFormat'),
    dict(
        type='Collect',
        keys=['img', 'img_metas', 'gt_3dlanes', 'gt_project_matrix', 'mask'])
]
dataset_config = dict(max_lanes=7, input_size=(360, 480))
data = dict(
    samples_per_gpu=2,
    workers_per_gpu=0,
    train=dict(
        type='APOLLOSIMDataset',
        data_root='data/ApolloSim',
        data_list='test2.txt',
        y_steps=[5, 10, 15, 20, 30, 40, 50, 60, 80, 100],
        dataset_config=dict(max_lanes=7, input_size=(360, 480)),
        split='standard',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Resize', img_scale=(480, 360), keep_ratio=False),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='MaskGenerate', input_size=(360, 480)),
            dict(type='LaneFormat'),
            dict(
                type='Collect',
                keys=[
                    'img', 'img_metas', 'gt_3dlanes', 'gt_project_matrix',
                    'mask'
                ])
        ]),
    test=dict(
        type='APOLLOSIMDataset',
        data_root='data/ApolloSim',
        data_list='test.txt',
        dataset_config=dict(max_lanes=7, input_size=(360, 480)),
        y_steps=[5, 10, 15, 20, 30, 40, 50, 60, 80, 100],
        split='standard',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(type='Resize', img_scale=(480, 360), keep_ratio=False),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='MaskGenerate', input_size=(360, 480)),
            dict(type='LaneFormat'),
            dict(
                type='Collect',
                keys=[
                    'img', 'img_metas', 'gt_3dlanes', 'gt_project_matrix',
                    'mask'
                ])
        ],
        test_mode=True))
model = dict(
    type='Anchor3DLane',
    backbone=dict(
        type='ResNetV1c',
        depth=18,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        dilations=(1, 1, 2, 4),
        strides=(1, 2, 1, 1),
        style='pytorch'),
    pretrained='pretrained/resnet18_v1c-b5776b93.pth',
    y_steps=[5, 10, 15, 20, 30, 40, 50, 60, 80, 100],
    feat_y_steps=[5, 10, 15, 20, 30, 40, 50, 60, 80, 100],
    anchor_cfg=dict(
        pitches=[5, 2, 1, 0, -1, -2, -5],
        yaws=[
            30, 20, 15, 10, 7, 5, 3, 1, 0, -1, -3, -5, -7, -10, -15, -20, -30
        ],
        num_x=45,
        distances=[3]),
    db_cfg=dict(
        org_h=1080,
        org_w=1920,
        resize_h=360,
        resize_w=480,
        ipm_h=208,
        ipm_w=128,
        pitch=3,
        cam_height=1.55,
        crop_y=0,
        K=[[2015.0, 0.0, 960.0], [0.0, 2015.0, 540.0], [0.0, 0.0, 1.0]],
        top_view_region=[[-10, 103], [10, 103], [-10, 3], [10, 3]],
        max_2dpoints=10),
    attn_dim=64,
    iter_reg=0,
    drop_out=0.0,
    num_heads=2,
    dim_feedforward=128,
    pre_norm=False,
    feat_size=(45, 60),
    num_category=2,
    loss_lane=dict(
        type='LaneLoss',
        loss_weights=dict(
            cls_loss=1, reg_losses_x=1, reg_losses_z=1, reg_losses_vis=1),
        assign_cfg=dict(
            type='TopkAssigner',
            pos_k=3,
            neg_k=450,
            anchor_len=10,
            metric='Euclidean'),
        anchor_len=10,
        anchor_steps=[5, 10, 15, 20, 30, 40, 50, 60, 80, 100]),
    train_cfg=dict(nms_thres=0, conf_threshold=0),
    test_cfg=dict(
        nms_thres=2,
        conf_threshold=0.5,
        test_conf=0.7,
        refine_vis=True,
        vis_thresh=0.5))
data_shuffle = True
optimizer = dict(type='Adam', lr=0.0001)
optimizer_config = dict()
lr_config = dict(policy='step', step=[45000], by_epoch=False)
runner = dict(type='IterBasedRunner', max_iters=50000)
checkpoint_config = dict(by_epoch=False, interval=2500)
log_config = dict(
    interval=10,
    hooks=[
        dict(type='TextLoggerHook', by_epoch=False),
        dict(type='TensorboardLoggerHook')
    ])
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = None
resume_from = None
workflow = [('train', 10000000)]
cudnn_benchmark = True
work_dir = 'output/apollosim/lanedt2/standard'
gpu_ids = range(0, 8)
auto_resume = True

2025-05-23 23:50:01,054 - mmseg - INFO - Set random seed to 291418059, deterministic: False
anchor: 4431
anchor: 4431
anchor: 4431
/home/zhaohui1.wang/github/Anchor3DLane/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is a deprecated, '
anchor: 4431
anchor: 4431
anchor: 4431
anchor: 4431
anchor: 4431
/home/zhaohui1.wang/github/Anchor3DLane/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is a deprecated, '
/home/zhaohui1.wang/github/Anchor3DLane/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is a deprecated, '
/home/zhaohui1.wang/github/Anchor3DLane/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is a deprecated, '
/home/zhaohui1.wang/github/Anchor3DLane/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is a deprecated, '
/home/zhaohui1.wang/github/Anchor3DLane/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is a deprecated, '
/home/zhaohui1.wang/github/Anchor3DLane/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is a deprecated, '
/home/zhaohui1.wang/github/Anchor3DLane/mmseg/models/backbones/resnet.py:431: UserWarning: DeprecationWarning: pretrained is a deprecated, please use "init_cfg" instead
  warnings.warn('DeprecationWarning: pretrained is a deprecated, '
2025-05-23 23:50:01,228 - mmcv - INFO - initialize ResNetV1c with init_cfg {'type': 'Pretrained', 'checkpoint': 'pretrained/resnet18_v1c-b5776b93.pth'}
2025-05-23 23:50:01,228 - mmcv - INFO - load model from: pretrained/resnet18_v1c-b5776b93.pth
2025-05-23 23:50:01,228 - mmcv - INFO - load checkpoint from local path: pretrained/resnet18_v1c-b5776b93.pth
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/runner/checkpoint.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(filename, map_location=map_location)
2025-05-23 23:50:01,234 - mmcv - INFO - initialize ResNetV1c with init_cfg {'type': 'Pretrained', 'checkpoint': 'pretrained/resnet18_v1c-b5776b93.pth'}
2025-05-23 23:50:01,234 - mmcv - INFO - load model from: pretrained/resnet18_v1c-b5776b93.pth
2025-05-23 23:50:01,234 - mmcv - INFO - initialize ResNetV1c with init_cfg {'type': 'Pretrained', 'checkpoint': 'pretrained/resnet18_v1c-b5776b93.pth'}
2025-05-23 23:50:01,234 - mmcv - INFO - load model from: pretrained/resnet18_v1c-b5776b93.pth
2025-05-23 23:50:01,235 - mmcv - INFO - load checkpoint from local path: pretrained/resnet18_v1c-b5776b93.pth
2025-05-23 23:50:01,235 - mmcv - INFO - initialize ResNetV1c with init_cfg {'type': 'Pretrained', 'checkpoint': 'pretrained/resnet18_v1c-b5776b93.pth'}
2025-05-23 23:50:01,235 - mmcv - INFO - load checkpoint from local path: pretrained/resnet18_v1c-b5776b93.pth
2025-05-23 23:50:01,235 - mmcv - INFO - load model from: pretrained/resnet18_v1c-b5776b93.pth
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/runner/checkpoint.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(filename, map_location=map_location)
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/runner/checkpoint.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(filename, map_location=map_location)
2025-05-23 23:50:01,236 - mmcv - INFO - load checkpoint from local path: pretrained/resnet18_v1c-b5776b93.pth
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/runner/checkpoint.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(filename, map_location=map_location)
2025-05-23 23:50:01,236 - mmcv - INFO - initialize ResNetV1c with init_cfg {'type': 'Pretrained', 'checkpoint': 'pretrained/resnet18_v1c-b5776b93.pth'}
2025-05-23 23:50:01,236 - mmcv - INFO - load model from: pretrained/resnet18_v1c-b5776b93.pth
2025-05-23 23:50:01,236 - mmcv - INFO - initialize ResNetV1c with init_cfg {'type': 'Pretrained', 'checkpoint': 'pretrained/resnet18_v1c-b5776b93.pth'}
2025-05-23 23:50:01,236 - mmcv - INFO - load model from: pretrained/resnet18_v1c-b5776b93.pth
2025-05-23 23:50:01,237 - mmcv - INFO - load checkpoint from local path: pretrained/resnet18_v1c-b5776b93.pth
2025-05-23 23:50:01,237 - mmcv - INFO - load checkpoint from local path: pretrained/resnet18_v1c-b5776b93.pth
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/runner/checkpoint.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(filename, map_location=map_location)
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/runner/checkpoint.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(filename, map_location=map_location)
2025-05-23 23:50:01,271 - mmcv - WARNING - The model and loaded state dict do not match exactly

unexpected key in source state_dict: fc.weight, fc.bias

2025-05-23 23:50:01,272 - mmcv - INFO - initialize ResNetV1c with init_cfg {'type': 'Pretrained', 'checkpoint': 'pretrained/resnet18_v1c-b5776b93.pth'}
2025-05-23 23:50:01,272 - mmcv - INFO - load model from: pretrained/resnet18_v1c-b5776b93.pth
2025-05-23 23:50:01,273 - mmcv - INFO - load checkpoint from local path: pretrained/resnet18_v1c-b5776b93.pth
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/runner/checkpoint.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(filename, map_location=map_location)
2025-05-23 23:50:01,275 - mmcv - INFO - initialize ResNetV1c with init_cfg {'type': 'Pretrained', 'checkpoint': 'pretrained/resnet18_v1c-b5776b93.pth'}
2025-05-23 23:50:01,275 - mmcv - INFO - load model from: pretrained/resnet18_v1c-b5776b93.pth
2025-05-23 23:50:01,276 - mmcv - INFO - load checkpoint from local path: pretrained/resnet18_v1c-b5776b93.pth
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/mmcv/runner/checkpoint.py:334: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(filename, map_location=map_location)
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.stem.0.weight - torch.Size([32, 3, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.stem.1.weight - torch.Size([32]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.stem.1.bias - torch.Size([32]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.stem.3.weight - torch.Size([32, 32, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.stem.4.weight - torch.Size([32]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.stem.4.bias - torch.Size([32]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.stem.6.weight - torch.Size([64, 32, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.stem.7.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.stem.7.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.layer1.0.conv1.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.layer1.0.bn1.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.layer1.0.bn1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.layer1.0.bn2.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.layer1.0.bn2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.layer1.1.conv1.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.layer1.1.bn1.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.layer1.1.bn1.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.layer1.1.bn2.weight - torch.Size([64]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.layer1.1.bn2.bias - torch.Size([64]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.layer2.0.conv1.weight - torch.Size([128, 64, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.layer2.0.bn1.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,280 - mmcv - INFO - 
backbone.layer2.0.bn1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer2.0.bn2.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer2.0.bn2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer2.0.downsample.0.weight - torch.Size([128, 64, 1, 1]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer2.0.downsample.1.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer2.0.downsample.1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer2.1.conv1.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer2.1.bn1.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer2.1.bn1.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer2.1.bn2.weight - torch.Size([128]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer2.1.bn2.bias - torch.Size([128]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer3.0.conv1.weight - torch.Size([256, 128, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer3.0.bn1.weight - torch.Size([256]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer3.0.bn1.bias - torch.Size([256]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer3.0.bn2.weight - torch.Size([256]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer3.0.bn2.bias - torch.Size([256]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer3.0.downsample.0.weight - torch.Size([256, 128, 1, 1]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer3.0.downsample.1.weight - torch.Size([256]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer3.0.downsample.1.bias - torch.Size([256]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer3.1.conv1.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer3.1.bn1.weight - torch.Size([256]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer3.1.bn1.bias - torch.Size([256]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer3.1.bn2.weight - torch.Size([256]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer3.1.bn2.bias - torch.Size([256]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer4.0.conv1.weight - torch.Size([512, 256, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer4.0.bn1.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer4.0.bn1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer4.0.bn2.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer4.0.bn2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer4.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer4.0.downsample.1.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer4.0.downsample.1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer4.1.conv1.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer4.1.bn1.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer4.1.bn1.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer4.1.bn2.weight - torch.Size([512]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
backbone.layer4.1.bn2.bias - torch.Size([512]): 
PretrainedInit: load from pretrained/resnet18_v1c-b5776b93.pth 
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
input_proj.weight - torch.Size([64, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
input_proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
transformer_layer.self_attn.in_proj_weight - torch.Size([192, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
transformer_layer.self_attn.in_proj_bias - torch.Size([192]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
transformer_layer.self_attn.out_proj.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
transformer_layer.self_attn.out_proj.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
transformer_layer.linear1.weight - torch.Size([128, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
transformer_layer.linear1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
transformer_layer.linear2.weight - torch.Size([64, 128]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
transformer_layer.linear2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
transformer_layer.norm1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
transformer_layer.norm1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
transformer_layer.norm2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,281 - mmcv - INFO - 
transformer_layer.norm2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
anchor_projection.weight - torch.Size([64, 64, 1, 1]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
anchor_projection.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
cls_layer.0.layer.0.weight - torch.Size([640, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
cls_layer.0.layer.0.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
cls_layer.0.layer.2.weight - torch.Size([640, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
cls_layer.0.layer.2.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
cls_layer.0.layer.4.weight - torch.Size([2, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
cls_layer.0.layer.4.bias - torch.Size([2]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
reg_x_layer.0.layer.0.weight - torch.Size([64, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
reg_x_layer.0.layer.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
reg_x_layer.0.layer.2.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
reg_x_layer.0.layer.2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
reg_x_layer.0.layer.4.weight - torch.Size([10, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
reg_x_layer.0.layer.4.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
reg_z_layer.0.layer.0.weight - torch.Size([64, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
reg_z_layer.0.layer.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
reg_z_layer.0.layer.2.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
reg_z_layer.0.layer.2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
reg_z_layer.0.layer.4.weight - torch.Size([10, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
reg_z_layer.0.layer.4.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
reg_vis_layer.0.layer.0.weight - torch.Size([64, 640]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
reg_vis_layer.0.layer.0.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
reg_vis_layer.0.layer.2.weight - torch.Size([64, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
reg_vis_layer.0.layer.2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
reg_vis_layer.0.layer.4.weight - torch.Size([10, 64]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmcv - INFO - 
reg_vis_layer.0.layer.4.bias - torch.Size([10]): 
The value is the same before and after calling `init_weights` of Anchor3DLane  
 
2025-05-23 23:50:01,282 - mmseg - INFO - Anchor3DLane(
  (backbone): ResNetV1c(
    (stem): Sequential(
      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU(inplace=True)
      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (5): ReLU(inplace=True)
      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (8): ReLU(inplace=True)
    )
    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
    (layer1): ResLayer(
      (0): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer2): ResLayer(
      (0): BasicBlock(
        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer3): ResLayer(
      (0): BasicBlock(
        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
    (layer4): ResLayer(
      (0): BasicBlock(
        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
        (downsample): Sequential(
          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
    )
  )
  init_cfg={'type': 'Pretrained', 'checkpoint': 'pretrained/resnet18_v1c-b5776b93.pth'}
  (position_embedding): PositionEmbeddingSine()
  (input_proj): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
  (transformer_layer): TransformerEncoderLayer(
    (self_attn): MultiheadAttention(
      (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)
    )
    (linear1): Linear(in_features=64, out_features=128, bias=True)
    (dropout): Dropout(p=0.0, inplace=False)
    (linear2): Linear(in_features=128, out_features=64, bias=True)
    (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)
    (dropout1): Dropout(p=0.0, inplace=False)
    (dropout2): Dropout(p=0.0, inplace=False)
  )
  (anchor_projection): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
  (cls_layer): ModuleList(
    (0): DecodeLayer(
      (layer): Sequential(
        (0): Linear(in_features=640, out_features=640, bias=True)
        (1): ReLU6()
        (2): Linear(in_features=640, out_features=640, bias=True)
        (3): ReLU6()
        (4): Linear(in_features=640, out_features=2, bias=True)
      )
    )
  )
  (reg_x_layer): ModuleList(
    (0): DecodeLayer(
      (layer): Sequential(
        (0): Linear(in_features=640, out_features=64, bias=True)
        (1): ReLU6()
        (2): Linear(in_features=64, out_features=64, bias=True)
        (3): ReLU6()
        (4): Linear(in_features=64, out_features=10, bias=True)
      )
    )
  )
  (reg_z_layer): ModuleList(
    (0): DecodeLayer(
      (layer): Sequential(
        (0): Linear(in_features=640, out_features=64, bias=True)
        (1): ReLU6()
        (2): Linear(in_features=64, out_features=64, bias=True)
        (3): ReLU6()
        (4): Linear(in_features=64, out_features=10, bias=True)
      )
    )
  )
  (reg_vis_layer): ModuleList(
    (0): DecodeLayer(
      (layer): Sequential(
        (0): Linear(in_features=640, out_features=64, bias=True)
        (1): ReLU6()
        (2): Linear(in_features=64, out_features=64, bias=True)
        (3): ReLU6()
        (4): Linear(in_features=64, out_features=10, bias=True)
      )
    )
  )
  (lane_loss): LaneLoss()
  (aux_loss): ModuleList()
)
Now loading annotations...
Now loading annotations...
Now loading annotations...
Now loading annotations...
Now loading annotations...
Now loading annotations...
0it [00:00, ?it/s]0it [00:00, ?it/s]0it [00:00, ?it/s]16it [00:00, 118149.41it/s]
after load annotation
find 16 samples in data/ApolloSim/data_lists/standard/test2.txt.
16it [00:00, 111291.65it/s]
after load annotation
find 16 samples in data/ApolloSim/data_lists/standard/test2.txt.
16it [00:00, 120482.70it/s]
after load annotation
find 16 samples in data/ApolloSim/data_lists/standard/test2.txt.
0it [00:00, ?it/s]0it [00:00, ?it/s]16it [00:00, 116711.07it/s]
after load annotation
find 16 samples in data/ApolloSim/data_lists/standard/test2.txt.
16it [00:00, 123589.07it/s]
after load annotation
find 16 samples in data/ApolloSim/data_lists/standard/test2.txt.
0it [00:00, ?it/s]16it [00:00, 114130.72it/s]
after load annotation
find 16 samples in data/ApolloSim/data_lists/standard/test2.txt.
Now loading annotations...
Now loading annotations...
0it [00:00, ?it/s]16it [00:00, 128315.23it/s]
after load annotation
find 16 samples in data/ApolloSim/data_lists/standard/test2.txt.
0it [00:00, ?it/s]16it [00:00, 127100.12it/s]
after load annotation
find 16 samples in data/ApolloSim/data_lists/standard/test2.txt.
2025-05-23 23:50:01,708 - mmseg - INFO - optimized parameters:
2025-05-23 23:50:01,708 - mmseg - INFO - backbone.stem.0.weight
2025-05-23 23:50:01,708 - mmseg - INFO - backbone.stem.1.weight
2025-05-23 23:50:01,708 - mmseg - INFO - backbone.stem.1.bias
2025-05-23 23:50:01,708 - mmseg - INFO - backbone.stem.3.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.stem.4.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.stem.4.bias
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.stem.6.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.stem.7.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.stem.7.bias
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer1.0.conv1.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer1.0.bn1.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer1.0.bn1.bias
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer1.0.conv2.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer1.0.bn2.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer1.0.bn2.bias
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer1.1.conv1.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer1.1.bn1.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer1.1.bn1.bias
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer1.1.conv2.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer1.1.bn2.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer1.1.bn2.bias
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer2.0.conv1.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer2.0.bn1.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer2.0.bn1.bias
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer2.0.conv2.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer2.0.bn2.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer2.0.bn2.bias
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer2.0.downsample.0.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer2.0.downsample.1.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer2.0.downsample.1.bias
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer2.1.conv1.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer2.1.bn1.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer2.1.bn1.bias
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer2.1.conv2.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer2.1.bn2.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer2.1.bn2.bias
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer3.0.conv1.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer3.0.bn1.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer3.0.bn1.bias
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer3.0.conv2.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer3.0.bn2.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer3.0.bn2.bias
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer3.0.downsample.0.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer3.0.downsample.1.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer3.0.downsample.1.bias
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer3.1.conv1.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer3.1.bn1.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer3.1.bn1.bias
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer3.1.conv2.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer3.1.bn2.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer3.1.bn2.bias
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer4.0.conv1.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer4.0.bn1.weight
2025-05-23 23:50:01,709 - mmseg - INFO - backbone.layer4.0.bn1.bias
2025-05-23 23:50:01,710 - mmseg - INFO - backbone.layer4.0.conv2.weight
2025-05-23 23:50:01,710 - mmseg - INFO - backbone.layer4.0.bn2.weight
2025-05-23 23:50:01,710 - mmseg - INFO - backbone.layer4.0.bn2.bias
2025-05-23 23:50:01,710 - mmseg - INFO - backbone.layer4.0.downsample.0.weight
2025-05-23 23:50:01,710 - mmseg - INFO - backbone.layer4.0.downsample.1.weight
2025-05-23 23:50:01,710 - mmseg - INFO - backbone.layer4.0.downsample.1.bias
2025-05-23 23:50:01,710 - mmseg - INFO - backbone.layer4.1.conv1.weight
2025-05-23 23:50:01,710 - mmseg - INFO - backbone.layer4.1.bn1.weight
2025-05-23 23:50:01,710 - mmseg - INFO - backbone.layer4.1.bn1.bias
2025-05-23 23:50:01,710 - mmseg - INFO - backbone.layer4.1.conv2.weight
2025-05-23 23:50:01,710 - mmseg - INFO - backbone.layer4.1.bn2.weight
2025-05-23 23:50:01,710 - mmseg - INFO - backbone.layer4.1.bn2.bias
2025-05-23 23:50:01,710 - mmseg - INFO - input_proj.weight
2025-05-23 23:50:01,710 - mmseg - INFO - input_proj.bias
2025-05-23 23:50:01,710 - mmseg - INFO - transformer_layer.self_attn.in_proj_weight
2025-05-23 23:50:01,710 - mmseg - INFO - transformer_layer.self_attn.in_proj_bias
2025-05-23 23:50:01,710 - mmseg - INFO - transformer_layer.self_attn.out_proj.weight
2025-05-23 23:50:01,710 - mmseg - INFO - transformer_layer.self_attn.out_proj.bias
2025-05-23 23:50:01,710 - mmseg - INFO - transformer_layer.linear1.weight
2025-05-23 23:50:01,710 - mmseg - INFO - transformer_layer.linear1.bias
2025-05-23 23:50:01,710 - mmseg - INFO - transformer_layer.linear2.weight
2025-05-23 23:50:01,710 - mmseg - INFO - transformer_layer.linear2.bias
2025-05-23 23:50:01,710 - mmseg - INFO - transformer_layer.norm1.weight
2025-05-23 23:50:01,710 - mmseg - INFO - transformer_layer.norm1.bias
2025-05-23 23:50:01,710 - mmseg - INFO - transformer_layer.norm2.weight
2025-05-23 23:50:01,710 - mmseg - INFO - transformer_layer.norm2.bias
2025-05-23 23:50:01,710 - mmseg - INFO - anchor_projection.weight
2025-05-23 23:50:01,710 - mmseg - INFO - anchor_projection.bias
2025-05-23 23:50:01,710 - mmseg - INFO - cls_layer.0.layer.0.weight
2025-05-23 23:50:01,710 - mmseg - INFO - cls_layer.0.layer.0.bias
2025-05-23 23:50:01,710 - mmseg - INFO - cls_layer.0.layer.2.weight
2025-05-23 23:50:01,710 - mmseg - INFO - cls_layer.0.layer.2.bias
2025-05-23 23:50:01,710 - mmseg - INFO - cls_layer.0.layer.4.weight
2025-05-23 23:50:01,710 - mmseg - INFO - cls_layer.0.layer.4.bias
2025-05-23 23:50:01,710 - mmseg - INFO - reg_x_layer.0.layer.0.weight
2025-05-23 23:50:01,710 - mmseg - INFO - reg_x_layer.0.layer.0.bias
2025-05-23 23:50:01,710 - mmseg - INFO - reg_x_layer.0.layer.2.weight
2025-05-23 23:50:01,710 - mmseg - INFO - reg_x_layer.0.layer.2.bias
2025-05-23 23:50:01,710 - mmseg - INFO - reg_x_layer.0.layer.4.weight
2025-05-23 23:50:01,710 - mmseg - INFO - reg_x_layer.0.layer.4.bias
2025-05-23 23:50:01,710 - mmseg - INFO - reg_z_layer.0.layer.0.weight
2025-05-23 23:50:01,710 - mmseg - INFO - reg_z_layer.0.layer.0.bias
2025-05-23 23:50:01,710 - mmseg - INFO - reg_z_layer.0.layer.2.weight
2025-05-23 23:50:01,710 - mmseg - INFO - reg_z_layer.0.layer.2.bias
2025-05-23 23:50:01,710 - mmseg - INFO - reg_z_layer.0.layer.4.weight
2025-05-23 23:50:01,710 - mmseg - INFO - reg_z_layer.0.layer.4.bias
2025-05-23 23:50:01,710 - mmseg - INFO - reg_vis_layer.0.layer.0.weight
2025-05-23 23:50:01,710 - mmseg - INFO - reg_vis_layer.0.layer.0.bias
2025-05-23 23:50:01,710 - mmseg - INFO - reg_vis_layer.0.layer.2.weight
2025-05-23 23:50:01,710 - mmseg - INFO - reg_vis_layer.0.layer.2.bias
2025-05-23 23:50:01,710 - mmseg - INFO - reg_vis_layer.0.layer.4.weight
2025-05-23 23:50:01,711 - mmseg - INFO - reg_vis_layer.0.layer.4.bias
2025-05-23 23:50:01,713 - mmseg - INFO - load checkpoint from local path: output/apollosim/lanedt2/standard/latest.pth
to run
to run
to runto run

2025-05-23 23:50:02,078 - mmseg - INFO - resumed from epoch: 2500, iter 4999
to run
2025-05-23 23:50:02,078 - mmseg - INFO - Start running, host: zhaohui1.wang@bare-20250217151813020-10-251-16-51, work_dir: /home/zhaohui1.wang/github/Anchor3DLane/output/apollosim/lanedt2/standard
2025-05-23 23:50:02,078 - mmseg - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_epoch:
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
(VERY_LOW    ) TensorboardLoggerHook              
 -------------------- 
2025-05-23 23:50:02,078 - mmseg - INFO - workflow: [('train', 10000000)], max: 50000 iters
2025-05-23 23:50:02,079 - mmseg - INFO - Checkpoints will be saved to /home/zhaohui1.wang/github/Anchor3DLane/output/apollosim/lanedt2/standard by HardDiskBackend.
2025-05-23 23:50:02.441258: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-05-23 23:50:02.453915: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1748015402.467853   29094 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1748015402.471915   29094 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-05-23 23:50:02.491431: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX512_FP16 AVX_VNNI AMX_TILE AMX_INT8 AMX_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/nn/functional.py:4373: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/nn/functional.py:4373: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/nn/functional.py:4373: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/nn/functional.py:4373: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
to run
to run
to run
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/nn/functional.py:4373: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/nn/functional.py:4373: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/nn/functional.py:4373: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
/home/zhaohui1.wang/miniconda3/envs/lane3d/lib/python3.9/site-packages/torch/nn/functional.py:4373: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
[rank0]:[W523 23:50:07.385712703 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank1]:[W523 23:50:07.386784979 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank2]:[W523 23:50:07.388175287 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank3]:[W523 23:50:07.389251018 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank5]:[W523 23:50:07.389516481 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank6]:[W523 23:50:07.389553435 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank7]:[W523 23:50:07.389890897 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[rank4]:[W523 23:50:07.390356214 reducer.cpp:1400] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
2025-05-23 23:50:07,540 - mmseg - INFO - Saving checkpoint at 5000 iterations
2025-05-23 23:50:08,008 - mmseg - INFO - Exp name: lanedt_test2.py
2025-05-23 23:50:08,008 - mmseg - INFO - Iter [5000/50000]	lr: 1.000e-04, eta: 16 days, 13:45:22, time: 3.182, data_time: 0.065, memory: 1034, batch_positives: 12.0000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-23 23:50:32,582 - mmseg - INFO - Iter [5010/50000]	lr: 1.000e-04, eta: 2 days, 16:04:15, time: 2.457, data_time: 2.047, memory: 1036, batch_positives: 11.8500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-23 23:50:53,796 - mmseg - INFO - Iter [5020/50000]	lr: 1.000e-04, eta: 1 day, 22:10:30, time: 2.121, data_time: 2.045, memory: 1036, batch_positives: 11.7000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-23 23:51:24,701 - mmseg - INFO - Iter [5030/50000]	lr: 1.000e-04, eta: 1 day, 19:43:35, time: 3.090, data_time: 2.047, memory: 1036, batch_positives: 11.4000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-23 23:51:50,889 - mmseg - INFO - Iter [5040/50000]	lr: 1.000e-04, eta: 1 day, 17:01:51, time: 2.619, data_time: 2.047, memory: 1036, batch_positives: 11.1000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-23 23:52:20,595 - mmseg - INFO - Iter [5050/50000]	lr: 1.000e-04, eta: 1 day, 16:15:04, time: 2.971, data_time: 2.047, memory: 1036, batch_positives: 11.2500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-23 23:52:53,289 - mmseg - INFO - Iter [5060/50000]	lr: 1.000e-04, eta: 1 day, 16:19:32, time: 3.264, data_time: 2.047, memory: 1036, batch_positives: 11.5500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-23 23:53:17,594 - mmseg - INFO - Iter [5070/50000]	lr: 1.000e-04, eta: 1 day, 14:55:08, time: 2.435, data_time: 2.049, memory: 1036, batch_positives: 12.0000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-23 23:53:49,379 - mmseg - INFO - Iter [5080/50000]	lr: 1.000e-04, eta: 1 day, 15:00:11, time: 3.179, data_time: 2.046, memory: 1036, batch_positives: 11.5500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-23 23:54:15,447 - mmseg - INFO - Iter [5090/50000]	lr: 1.000e-04, eta: 1 day, 14:16:59, time: 2.607, data_time: 2.048, memory: 1036, batch_positives: 11.2500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-23 23:54:46,185 - mmseg - INFO - Iter [5100/50000]	lr: 1.000e-04, eta: 1 day, 14:14:45, time: 3.046, data_time: 2.047, memory: 1036, batch_positives: 12.0000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-23 23:55:07,514 - mmseg - INFO - Iter [5110/50000]	lr: 1.000e-04, eta: 1 day, 13:13:12, time: 2.161, data_time: 2.072, memory: 1036, batch_positives: 11.8500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-23 23:55:37,960 - mmseg - INFO - Iter [5120/50000]	lr: 1.000e-04, eta: 1 day, 13:16:24, time: 3.045, data_time: 2.048, memory: 1036, batch_positives: 11.5500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-23 23:55:59,280 - mmseg - INFO - Iter [5130/50000]	lr: 1.000e-04, eta: 1 day, 12:26:56, time: 2.132, data_time: 2.045, memory: 1036, batch_positives: 11.1000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-23 23:56:34,793 - mmseg - INFO - Iter [5140/50000]	lr: 1.000e-04, eta: 1 day, 12:59:41, time: 3.551, data_time: 2.047, memory: 1036, batch_positives: 10.8000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-23 23:57:04,436 - mmseg - INFO - Iter [5150/50000]	lr: 1.000e-04, eta: 1 day, 12:58:58, time: 2.964, data_time: 2.045, memory: 1036, batch_positives: 11.8500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0003
2025-05-23 23:57:35,659 - mmseg - INFO - Iter [5160/50000]	lr: 1.000e-04, eta: 1 day, 13:05:34, time: 3.121, data_time: 2.045, memory: 1036, batch_positives: 12.1500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0002, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0003
2025-05-23 23:58:00,638 - mmseg - INFO - Iter [5170/50000]	lr: 1.000e-04, eta: 1 day, 12:44:08, time: 2.499, data_time: 2.049, memory: 1036, batch_positives: 11.7000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0002, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0004
2025-05-23 23:58:38,753 - mmseg - INFO - Iter [5180/50000]	lr: 1.000e-04, eta: 1 day, 13:19:12, time: 3.812, data_time: 2.045, memory: 1036, batch_positives: 11.5500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0004, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0005
2025-05-23 23:59:04,156 - mmseg - INFO - Iter [5190/50000]	lr: 1.000e-04, eta: 1 day, 13:00:48, time: 2.540, data_time: 2.047, memory: 1036, batch_positives: 11.7000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0004, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0006
2025-05-23 23:59:38,563 - mmseg - INFO - Iter [5200/50000]	lr: 1.000e-04, eta: 1 day, 13:17:37, time: 3.440, data_time: 2.046, memory: 1036, batch_positives: 11.2500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0003, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0004
2025-05-24 00:00:16,131 - mmseg - INFO - Iter [5210/50000]	lr: 1.000e-04, eta: 1 day, 13:44:03, time: 3.758, data_time: 2.047, memory: 1036, batch_positives: 11.4000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0003, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0004
2025-05-24 00:00:45,907 - mmseg - INFO - Iter [5220/50000]	lr: 1.000e-04, eta: 1 day, 13:41:41, time: 2.978, data_time: 2.046, memory: 1036, batch_positives: 10.8000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0003, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0004
2025-05-24 00:01:15,853 - mmseg - INFO - Iter [5230/50000]	lr: 1.000e-04, eta: 1 day, 13:39:54, time: 2.991, data_time: 2.045, memory: 1036, batch_positives: 11.7000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0003, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0004
2025-05-24 00:01:44,030 - mmseg - INFO - Iter [5240/50000]	lr: 1.000e-04, eta: 1 day, 13:32:55, time: 2.819, data_time: 2.048, memory: 1036, batch_positives: 11.7000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0003, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0004
2025-05-24 00:02:16,506 - mmseg - INFO - Iter [5250/50000]	lr: 1.000e-04, eta: 1 day, 13:39:12, time: 3.249, data_time: 2.047, memory: 1036, batch_positives: 11.8500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0003, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0005
2025-05-24 00:02:52,111 - mmseg - INFO - Iter [5260/50000]	lr: 1.000e-04, eta: 1 day, 13:53:48, time: 3.558, data_time: 2.045, memory: 1036, batch_positives: 11.8500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0003, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0004
2025-05-24 00:03:21,526 - mmseg - INFO - Iter [5270/50000]	lr: 1.000e-04, eta: 1 day, 13:50:26, time: 2.945, data_time: 2.047, memory: 1036, batch_positives: 11.5500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0002, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0004
2025-05-24 00:03:56,200 - mmseg - INFO - Iter [5280/50000]	lr: 1.000e-04, eta: 1 day, 14:01:07, time: 3.467, data_time: 2.046, memory: 1036, batch_positives: 11.7000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0002, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0004
2025-05-24 00:04:31,141 - mmseg - INFO - Iter [5290/50000]	lr: 1.000e-04, eta: 1 day, 14:11:42, time: 3.494, data_time: 2.044, memory: 1036, batch_positives: 12.0000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0002, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0004
2025-05-24 00:05:04,785 - mmseg - INFO - Iter [5300/50000]	lr: 1.000e-04, eta: 1 day, 14:17:36, time: 3.335, data_time: 2.045, memory: 1036, batch_positives: 12.1500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0002, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0003
2025-05-24 00:05:35,840 - mmseg - INFO - Iter [5310/50000]	lr: 1.000e-04, eta: 1 day, 14:18:19, time: 3.135, data_time: 2.075, memory: 1036, batch_positives: 11.8500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0002, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0003
2025-05-24 00:06:11,296 - mmseg - INFO - Iter [5320/50000]	lr: 1.000e-04, eta: 1 day, 14:28:28, time: 3.545, data_time: 2.046, memory: 1036, batch_positives: 10.8000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0002, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0003
2025-05-24 00:06:40,526 - mmseg - INFO - Iter [5330/50000]	lr: 1.000e-04, eta: 1 day, 14:23:58, time: 2.923, data_time: 2.045, memory: 1036, batch_positives: 11.4000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0002, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0003
2025-05-24 00:07:07,253 - mmseg - INFO - Iter [5340/50000]	lr: 1.000e-04, eta: 1 day, 14:14:15, time: 2.673, data_time: 2.045, memory: 1036, batch_positives: 11.4000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0002, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0003
2025-05-24 00:07:39,592 - mmseg - INFO - Iter [5350/50000]	lr: 1.000e-04, eta: 1 day, 14:16:20, time: 3.204, data_time: 2.045, memory: 1036, batch_positives: 11.7000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0002, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0003
2025-05-24 00:08:11,992 - mmseg - INFO - Iter [5360/50000]	lr: 1.000e-04, eta: 1 day, 14:19:36, time: 3.269, data_time: 2.076, memory: 1036, batch_positives: 11.2500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0002, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0003
2025-05-24 00:08:42,824 - mmseg - INFO - Iter [5370/50000]	lr: 1.000e-04, eta: 1 day, 14:18:51, time: 3.079, data_time: 2.046, memory: 1036, batch_positives: 11.7000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0002, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0003
2025-05-24 00:09:11,955 - mmseg - INFO - Iter [5380/50000]	lr: 1.000e-04, eta: 1 day, 14:14:57, time: 2.917, data_time: 2.049, memory: 1036, batch_positives: 12.0000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0002, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0003
2025-05-24 00:09:42,475 - mmseg - INFO - Iter [5390/50000]	lr: 1.000e-04, eta: 1 day, 14:13:47, time: 3.052, data_time: 2.045, memory: 1036, batch_positives: 11.4000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0002, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0003
2025-05-24 00:10:15,897 - mmseg - INFO - Iter [5400/50000]	lr: 1.000e-04, eta: 1 day, 14:18:02, time: 3.342, data_time: 2.045, memory: 1036, batch_positives: 11.5500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0002, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0003
2025-05-24 00:10:44,841 - mmseg - INFO - Iter [5410/50000]	lr: 1.000e-04, eta: 1 day, 14:13:57, time: 2.895, data_time: 2.044, memory: 1036, batch_positives: 11.7000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0002, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0003
2025-05-24 00:11:18,930 - mmseg - INFO - Iter [5420/50000]	lr: 1.000e-04, eta: 1 day, 14:19:08, time: 3.409, data_time: 2.046, memory: 1036, batch_positives: 11.7000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0002, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0003
2025-05-24 00:11:47,128 - mmseg - INFO - Iter [5430/50000]	lr: 1.000e-04, eta: 1 day, 14:13:52, time: 2.819, data_time: 2.045, memory: 1036, batch_positives: 12.1500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0003
2025-05-24 00:12:18,861 - mmseg - INFO - Iter [5440/50000]	lr: 1.000e-04, eta: 1 day, 14:14:44, time: 3.170, data_time: 2.047, memory: 1036, batch_positives: 11.5500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:12:48,365 - mmseg - INFO - Iter [5450/50000]	lr: 1.000e-04, eta: 1 day, 14:11:59, time: 2.954, data_time: 2.048, memory: 1036, batch_positives: 11.4000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0003
2025-05-24 00:13:20,211 - mmseg - INFO - Iter [5460/50000]	lr: 1.000e-04, eta: 1 day, 14:13:03, time: 3.185, data_time: 2.045, memory: 1036, batch_positives: 10.8000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:13:55,555 - mmseg - INFO - Iter [5470/50000]	lr: 1.000e-04, eta: 1 day, 14:19:05, time: 3.505, data_time: 2.046, memory: 1036, batch_positives: 11.8500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:14:28,346 - mmseg - INFO - Iter [5480/50000]	lr: 1.000e-04, eta: 1 day, 14:21:22, time: 3.279, data_time: 2.075, memory: 1036, batch_positives: 12.1500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:15:01,792 - mmseg - INFO - Iter [5490/50000]	lr: 1.000e-04, eta: 1 day, 14:24:58, time: 3.374, data_time: 2.074, memory: 1036, batch_positives: 12.0000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:15:34,991 - mmseg - INFO - Iter [5500/50000]	lr: 1.000e-04, eta: 1 day, 14:27:36, time: 3.320, data_time: 2.044, memory: 1036, batch_positives: 11.7000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:16:10,152 - mmseg - INFO - Iter [5510/50000]	lr: 1.000e-04, eta: 1 day, 14:32:54, time: 3.512, data_time: 2.045, memory: 1036, batch_positives: 11.7000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:16:41,538 - mmseg - INFO - Iter [5520/50000]	lr: 1.000e-04, eta: 1 day, 14:32:42, time: 3.142, data_time: 2.049, memory: 1036, batch_positives: 10.9500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:17:15,540 - mmseg - INFO - Iter [5530/50000]	lr: 1.000e-04, eta: 1 day, 14:36:05, time: 3.399, data_time: 2.044, memory: 1036, batch_positives: 11.1000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:17:41,271 - mmseg - INFO - Iter [5540/50000]	lr: 1.000e-04, eta: 1 day, 14:28:01, time: 2.574, data_time: 2.046, memory: 1036, batch_positives: 11.4000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:18:15,947 - mmseg - INFO - Iter [5550/50000]	lr: 1.000e-04, eta: 1 day, 14:32:15, time: 3.467, data_time: 2.045, memory: 1036, batch_positives: 11.4000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:18:47,976 - mmseg - INFO - Iter [5560/50000]	lr: 1.000e-04, eta: 1 day, 14:32:25, time: 3.173, data_time: 2.045, memory: 1036, batch_positives: 10.9500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:19:21,858 - mmseg - INFO - Iter [5570/50000]	lr: 1.000e-04, eta: 1 day, 14:35:41, time: 3.414, data_time: 2.076, memory: 1036, batch_positives: 11.1000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:19:57,129 - mmseg - INFO - Iter [5580/50000]	lr: 1.000e-04, eta: 1 day, 14:40:18, time: 3.531, data_time: 2.049, memory: 1036, batch_positives: 11.8500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:20:29,923 - mmseg - INFO - Iter [5590/50000]	lr: 1.000e-04, eta: 1 day, 14:41:36, time: 3.279, data_time: 2.045, memory: 1036, batch_positives: 11.5500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:20:59,649 - mmseg - INFO - Iter [5600/50000]	lr: 1.000e-04, eta: 1 day, 14:39:03, time: 2.972, data_time: 2.046, memory: 1036, batch_positives: 11.5500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:21:31,731 - mmseg - INFO - Iter [5610/50000]	lr: 1.000e-04, eta: 1 day, 14:39:26, time: 3.209, data_time: 2.048, memory: 1036, batch_positives: 12.1500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:22:04,307 - mmseg - INFO - Iter [5620/50000]	lr: 1.000e-04, eta: 1 day, 14:40:22, time: 3.258, data_time: 2.045, memory: 1036, batch_positives: 11.8500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0000, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:22:29,274 - mmseg - INFO - Iter [5630/50000]	lr: 1.000e-04, eta: 1 day, 14:32:21, time: 2.496, data_time: 2.045, memory: 1036, batch_positives: 11.7000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:22:56,929 - mmseg - INFO - Iter [5640/50000]	lr: 1.000e-04, eta: 1 day, 14:27:39, time: 2.766, data_time: 2.045, memory: 1036, batch_positives: 11.1000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0000, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:23:28,134 - mmseg - INFO - Iter [5650/50000]	lr: 1.000e-04, eta: 1 day, 14:27:07, time: 3.120, data_time: 2.043, memory: 1036, batch_positives: 11.2500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:23:56,246 - mmseg - INFO - Iter [5660/50000]	lr: 1.000e-04, eta: 1 day, 14:23:08, time: 2.812, data_time: 2.044, memory: 1036, batch_positives: 11.8500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:24:28,260 - mmseg - INFO - Iter [5670/50000]	lr: 1.000e-04, eta: 1 day, 14:23:33, time: 3.201, data_time: 2.045, memory: 1036, batch_positives: 12.3000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:24:56,387 - mmseg - INFO - Iter [5680/50000]	lr: 1.000e-04, eta: 1 day, 14:19:43, time: 2.812, data_time: 2.045, memory: 1036, batch_positives: 11.8500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:25:26,440 - mmseg - INFO - Iter [5690/50000]	lr: 1.000e-04, eta: 1 day, 14:18:03, time: 3.005, data_time: 2.046, memory: 1036, batch_positives: 12.0000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:25:55,995 - mmseg - INFO - Iter [5700/50000]	lr: 1.000e-04, eta: 1 day, 14:15:52, time: 2.953, data_time: 2.044, memory: 1036, batch_positives: 11.4000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:26:24,789 - mmseg - INFO - Iter [5710/50000]	lr: 1.000e-04, eta: 1 day, 14:12:59, time: 2.882, data_time: 2.047, memory: 1036, batch_positives: 11.2500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:26:54,980 - mmseg - INFO - Iter [5720/50000]	lr: 1.000e-04, eta: 1 day, 14:11:34, time: 3.019, data_time: 2.045, memory: 1036, batch_positives: 11.2500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:27:27,763 - mmseg - INFO - Iter [5730/50000]	lr: 1.000e-04, eta: 1 day, 14:12:48, time: 3.278, data_time: 2.045, memory: 1036, batch_positives: 12.3000, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:28:00,498 - mmseg - INFO - Iter [5740/50000]	lr: 1.000e-04, eta: 1 day, 14:13:56, time: 3.274, data_time: 2.045, memory: 1036, batch_positives: 10.9500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
2025-05-24 00:28:26,784 - mmseg - INFO - Iter [5750/50000]	lr: 1.000e-04, eta: 1 day, 14:08:40, time: 2.626, data_time: 2.045, memory: 1036, batch_positives: 12.1500, batch_negatives: 450.0000, cls_loss: 0.0001, reg_losses_x: 0.0001, reg_losses_z: 0.0000, reg_losses_vis: 0.0000, loss: 0.0002
